{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = list(stopwords.words('english')) \n",
    "\n",
    "def parse_file(text_file):    \n",
    "    pat = re.compile(r'^(\\d\\d\\/\\d\\d\\/\\d\\d.*?)(?=^^\\d\\d\\/\\d\\d\\/\\d\\d|\\Z)', re.S | re.M)\n",
    "    with open(text_file,encoding='utf8') as f:\n",
    "        data = [m.group(1).strip().replace('\\n', ' ') for m in pat.finditer(f.read())]\n",
    "    sender = []; message = []; datetime = []\n",
    "    for row in data:\n",
    "        datetime.append(row.split(' - ')[0])\n",
    "        try:\n",
    "            s = re.search('m - (.*?):', row).group(1)\n",
    "            sender.append(s)\n",
    "        except:\n",
    "            sender.append('')\n",
    "        try:\n",
    "            message.append(row.split(': ', 1)[1])\n",
    "        except:\n",
    "            message.append('')\n",
    "    df = pd.DataFrame(zip(datetime, sender, message), columns=['timestamp', 'sender', 'message'])\n",
    "    df['timestamp'] = pd.to_datetime(df.timestamp, format='%d/%m/%y, %I:%M %p')\n",
    "    df = df[df.sender != ''].reset_index(drop=True)    \n",
    "    return df\n",
    "\n",
    "def dftostring(df):\n",
    "    messages = ' '.join(df.values)\n",
    "    messages = messages.lower()\n",
    "    messages = messages.strip()\n",
    "    messages = messages.replace('<media omitted>','media_omitted')\n",
    "    return(messages)\n",
    "    \n",
    "def getwordscount(messages,top=None):\n",
    "    finalCount = Counter()\n",
    "    #words = [w for w in messages.split(\" \") if w not in stop_words]\n",
    "    words = [w for w in word_tokenize(messages) if w not in stop_words]\n",
    "    finalCount.update(words)  # update final count using the words list\n",
    "    if top:\n",
    "        return finalCount.most_common(top)\n",
    "    else:\n",
    "        return finalCount \n",
    "    \n",
    "# def count_emoji(countall):\n",
    "#     emoji_lst = []\n",
    "#     topemoji = [for i in countall if i in emojilst]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_file('chat.txt')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message send by All is 1935\n",
      "Top 50 words: [('media_omitted', 233), ('?', 188), ('h', 171), ('hai', 159), (':', 152), ('https', 124), ('ky', 90), ('ka', 84), ('.', 80), ('nhi', 77), ('ha', 73), ('kya', 64), ('bhi', 63), ('ko', 56), ('mai', 55), (',', 55), ('nai', 51), ('main', 49), ('...', 48), ('fir', 46), ('tu', 44), ('na', 42), ('ek', 39), ('raha', 38), ('kuch', 38), ('hu', 37), ('tha', 34), ('hi', 34), ('ho', 33), ('kr', 33), ('p', 33), ('n', 32), ('ke', 32), ('-', 32), ('abe', 31), ('kar', 30), ('k', 29), ('wo', 28), ('yeh', 28), ('acha', 28), ('toh', 26), ('bol', 25), ('pe', 25), ('voh', 25), ('app', 24), ('hua', 24), ('se', 24), ('atharv', 24), ('sahi', 22), (')', 22)]\n",
      "\n",
      "Message send by Kanak Dahake Jr. is 825\n",
      "Top 50 words: [('?', 156), ('hai', 133), ('media_omitted', 92), ('kya', 61), (':', 56), ('ka', 52), ('nai', 51), ('.', 43), ('https', 43), ('mai', 41), ('ha', 39), ('na', 29), ('yeh', 28), ('voh', 25), ('abe', 24), ('ko', 24), ('toh', 23), ('pe', 23), ('kar', 22), ('ke', 22), ('ho', 21), ('sahi', 21), ('bhi', 21), ('abhi', 19), ('raha', 19), ('fir', 19), ('hu', 18), ('kuch', 18), ('ek', 18), ('ahe', 16), ('ðŸ˜‚', 16), ('gaya', 16), ('yaar', 16), (',', 16), ('vala', 15), ('hi', 15), ('tha', 15), ('chalega', 15), ('ðŸ˜‚ðŸ˜‚', 14), ('bahut', 14), ('aur', 13), ('arey', 13), ('se', 13), ('ðŸ˜…', 13), ('tu', 13), ('kiya', 12), ('de', 12), ('atharv', 12), ('karna', 12), ('mujhe', 11)]\n",
      "\n",
      "Message send by P1 is 1110\n",
      "Top 50 words: [('h', 170), ('media_omitted', 141), (':', 96), ('ky', 90), ('https', 81), ('nhi', 77), ('main', 49), ('...', 48), ('bhi', 42), (',', 39), ('.', 37), ('ha', 34), ('kr', 33), ('p', 33), ('n', 32), ('ka', 32), ('?', 32), ('ko', 32), ('tu', 31), ('k', 29), ('-', 28), ('wo', 27), ('fir', 27), ('hai', 26), ('acha', 23), ('ek', 21), ('kuch', 20), ('raha', 19), ('hu', 19), ('tha', 19), ('hi', 19), ('ok', 17), ('hua', 16), (')', 15), ('mai', 14), ('bol', 14), ('thik', 14), ('krte', 14), ('kam', 14), ('app', 14), ('wala', 14), ('yr', 13), ('krta', 13), ('koi', 13), ('na', 13), ('kl', 13), ('use', 13), ('atta', 12), ('ab', 12), ('paise', 12)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_analysis(name,df_s):\n",
    "    print(f'Message send by {name} is {df_s.shape[0]}')\n",
    "    allmessages_text = dftostring(df_s['message'])\n",
    "    countaall = getwordscount(allmessages_text)\n",
    "    #print(countaall)\n",
    "    print('Top 50 words:',getwordscount(allmessages_text,50))\n",
    "    print('')\n",
    "    \n",
    "sender = list(df.sender.unique())\n",
    "generate_analysis('All',df)\n",
    "for s in sender:\n",
    "    generate_analysis(s,df[df.sender==s])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
